{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd82d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "fastaFile = 'Genomes/DOUBLETESTER.fasta'\n",
    "Mito = 'Mitochondria_NC_012920_1.fasta'\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "GENOMES = 'Genomes/' # File path to where your genome is located\n",
    "#######################################################################\n",
    "RESULTSFILEPATH = 'Results'\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "#Global integers\n",
    "WINDOWVAL = 25\n",
    "THRESHOLDVAL = 2.0\n",
    "\n",
    "\n",
    "# Global strings\n",
    "G4HUNTER = 'G4HunterEDITED.py'\n",
    "\n",
    "\n",
    "# Output stats globals\n",
    "WINDOW = 'Window'\n",
    "THRESHOLD = 'Threshold'\n",
    "NPQS = 'Number of PQS'\n",
    "BP = 'Base Pairs'\n",
    "NGC = 'Number of GCs'\n",
    "PGC = 'Percentage of GCs'\n",
    "FRQ = 'Frequency of PQS'\n",
    "SPECIES = 'Species'\n",
    "\n",
    "# G4 Result .txt file to Database Globals\n",
    "SEQ_ID = 'Sequence_ID'\n",
    "START = 'Start'\n",
    "END = 'End'\n",
    "SEQUENCE = 'Sequence'\n",
    "LENGTH = 'Length'\n",
    "SCORE = 'Score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0131bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def process_txt_file(file_path):\n",
    "    data = []\n",
    "    current_sequence = None\n",
    "    PQS = 0\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # If the line starts with '>', it indicates a new sequence section\n",
    "            if line.startswith('>'):\n",
    "                current_sequence = line[1:]  # Remove '>' and store the sequence identifier\n",
    "            elif line and not line.startswith(START):\n",
    "                # Process the data lines\n",
    "                parts = line.split()\n",
    "                if len(parts) == 5:  # Ensures correct number of columns\n",
    "                    start, end, sequence, length, score = parts\n",
    "                    data.append({\n",
    "                        SEQ_ID: current_sequence,\n",
    "                        START: int(start),\n",
    "                        END: int(end),\n",
    "                        SEQUENCE: sequence,\n",
    "                        LENGTH: int(length),\n",
    "                        SCORE: float(score)\n",
    "                    })\n",
    "                elif len(parts) == 6:  # Ensures correct number of columns\n",
    "                    start, end, sequence, length, score, nbr = parts\n",
    "                    data.append({\n",
    "                        SEQ_ID: current_sequence,\n",
    "                        START: int(start),\n",
    "                        END: int(end),\n",
    "                        SEQUENCE: sequence,\n",
    "                        LENGTH: int(length),\n",
    "                        SCORE: float(score)\n",
    "                    })\n",
    "                    \n",
    "                    PQS += int(nbr) # Save number of putative quadruplex sequences\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    #df = pd.DataFrame(data)\n",
    "    return PQS\n",
    "\n",
    "def runG4(inputFile):\n",
    "    print('Running G4Hunter:', inputFile)\n",
    "    result = subprocess.run(\n",
    "    ['python3', G4HUNTER, '-i', inputFile, '-o', RESULTSFILEPATH, '-w', str(WINDOWVAL), '-s', str(THRESHOLDVAL)],\n",
    "                        capture_output=True, text=True)\n",
    "    return result.stdout.strip()\n",
    "\n",
    "\n",
    "def overallStats(filePath):\n",
    "    outputStats = {NPQS:0, BP: 0, NGC:0, PGC:0.0, FRQ: 0.0, WINDOW:WINDOWVAL, THRESHOLD:THRESHOLDVAL}\n",
    "    \n",
    "    # Parse all sequences in the file\n",
    "    for record in SeqIO.parse(filePath, \"fasta\"):\n",
    "        sequence = record.seq.upper()  # Convert to uppercase\n",
    "        outputStats[BP] += len(sequence)\n",
    "        outputStats[NGC] += sequence.count(\"G\") + sequence.count(\"C\")\n",
    "    return outputStats\n",
    "\n",
    "def findFastaFiles(directory):\n",
    "    # Define the FASTA file extensions you want to search for\n",
    "    fastaExtensions = ['*.fasta', '*.fa', '*.fna', '*.ffn', '*.faa', '*.frn']\n",
    "    \n",
    "    # Initialize an empty list to store the file paths\n",
    "    fastaFiles = []\n",
    "    \n",
    "    # Iterate over each file extension pattern\n",
    "    for ext in fastaExtensions:\n",
    "        # Use glob to search for files matching the pattern within the directory and its subdirectories\n",
    "        files = glob.glob(os.path.join(directory, '**', ext), recursive=True)\n",
    "        # Append found files to the list\n",
    "        fastaFiles.extend(files)\n",
    "    \n",
    "    return fastaFiles\n",
    "\n",
    "def fullStop(filepath):\n",
    "    # Separate the directory from the filename\n",
    "    directory, filename = os.path.split(filepath)\n",
    "\n",
    "    # Split the filename into the name and extension\n",
    "    name, extension = os.path.splitext(filename)\n",
    "\n",
    "    # Replace dots in the name part\n",
    "    new_name = name.replace(\".\", \"_\")\n",
    "\n",
    "    # Combine the modified name with the original extension\n",
    "    new_filename = new_name + extension\n",
    "\n",
    "    # Join the directory with the new filename to form the full new path\n",
    "    new_file_path = os.path.join(directory, new_filename)\n",
    "    os.rename(filepath, new_file_path)\n",
    "\n",
    "    return new_file_path\n",
    "    \n",
    "def extractSpecies(filepath):\n",
    "\n",
    "    # Split the filepath to get the relevant folder name\n",
    "    parts = filepath.split('/')\n",
    "    \n",
    "    # Extract genus and species\n",
    "    genus = parts[1].split('_')[0]  # Phytomonas\n",
    "    \n",
    "    species = parts[2]  # serpens 9T\n",
    "    \n",
    "    # Create the scientific name abbreviation\n",
    "    scientific_name = f\"{genus[0]}.{species}\"\n",
    "\n",
    "    return scientific_name\n",
    "\n",
    "\n",
    "\n",
    "def main(filePath):\n",
    "    return runG4(filePath), overallStats(filePath)\n",
    "\n",
    "\n",
    "###############Main Function##############\n",
    "\n",
    "def assassinate(filePath):\n",
    "    \n",
    "    # Make list of all files, iterate, produce the filepath and stats, save the overall stats \n",
    "    # in the same folder as the generated file path. \n",
    "    \n",
    "    for file in findFastaFiles(filePath):\n",
    "        print('Processing:', file)\n",
    "        generatedFilepath, overallStats = main(file)\n",
    "        if generatedFilepath=='':\n",
    "            print(file, 'had issues. Renaming file')\n",
    "            \n",
    "            generatedFilepath, overallStats = main(fullStop(file))\n",
    "            if generatedFilepath=='':\n",
    "                print('COMPLETE FAILURE OF:', file)\n",
    "                continue\n",
    "        overallStats[NPQS] = process_txt_file(generatedFilepath)\n",
    "        overallStats[PGC] = overallStats[NGC]/overallStats[BP]\n",
    "        overallStats[FRQ] = overallStats[NPQS]/overallStats[BP]\n",
    "        #overallStats[SPECIES] = extractSpecies(file)\n",
    "        \n",
    "        \n",
    "        # Save output data\n",
    "        directory = os.path.dirname(generatedFilepath)\n",
    "        base_name = os.path.splitext(os.path.basename(generatedFilepath))[0]\n",
    "        csv_file_name = f\"{base_name}.csv\"\n",
    "        csv_file_path = os.path.join(directory, csv_file_name)\n",
    "        df = pd.DataFrame([overallStats])\n",
    "        df.to_csv(csv_file_path, index=False)\n",
    "        print('Saved to', csv_file_path)\n",
    "    print('###########################')\n",
    "    print('#####Analysis Complete#####')\n",
    "    print('###########################')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113ec35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6381d7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: TEST/Leishmania/mexicana/GCA_000234665_4_ASM23466v4_genomic.fna\n",
      "Running G4Hunter: TEST/Leishmania/mexicana/GCA_000234665_4_ASM23466v4_genomic.fna\n",
      "Saved to TODAYSTESTRESULTS/Results_GCA_000234665_4_ASM23466v4_genomic/GCA_000234665_4_ASM23466v4_genomic-Merged.csv\n",
      "###########################\n",
      "#####Analysis Complete#####\n",
      "###########################\n"
     ]
    }
   ],
   "source": [
    "assassinate(GENOMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac68bdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
